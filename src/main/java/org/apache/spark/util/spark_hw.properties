# spark properties
spark.yarn.jar=hdfs://hdfs://hacluster/user/root/tipdm/tipdm/spark-assembly-1.5.1-hadoop2.7.2.jar
spark.yarn.scheduler.heartbeat.interval-ms=1000
spark.yarn.appMasterEnv.SPARK_DIST_CLASSPATH=/opt/hadoopclient_new/Yarn/config:/opt/hadoopclient_new/HDFS/hadoop/etc/hadoop:/opt/hadoopclient_new/HDFS/hadoop/etc/hadoop:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/common/lib/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/common/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/hdfs:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/hdfs/lib/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/hdfs/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/yarn/lib/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/yarn/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/mapreduce/lib/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/mapreduce/*:/opt/hadoopclient_new/HDFS/hadoop/contrib/capacity-scheduler/*.jar:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/tools/lib/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/yarn/*:/opt/hadoopclient_new/HDFS/hadoop/share/hadoop/yarn/lib/*
#spark.driver.memory=512M
#spark.num.executors=3
#spark.executor.core=1
#spark.executor.memory=720M
#spark.driver.extraJavaOptions=-XX:MaxPermSize=1024m
#spark.jar=hdfs://hacluster/user/root/tipdm/example-1.0-SNAPSHOT.jar
spark.yarn.isPython=true
spark.files=hdfs://hacluster/user/root/tipdm/yarn-site.xml,hdfs://hacluster/user/root/tipdm/hive-site.xml,hdfs://hacluster/user/root/tipdm/core-site.xml,hdfs://hacluster/user/root/tipdm/hdfs-site.xml,hdfs://hacluster/user/root/tipdm/mapred-site.xml,hdfs://hacluster/user/root/tipdm/spark-defaults.conf

##### other params
spark.submit.timeout=50
spark.job.check.interval=5